
一 九大数据类型
1 String
数据结构:底层数据结构为字符数组
适用场景:缓存，限流，计数器，分布式锁，分布式Session
2 list
数据结构:快速链表（压缩链表+链表）
适用场景:微博关注人时间轴列表，简单队列
3 Hash
数据结构:数组+链表
ziplist（压缩列表）：当哈希类型中元素个数小于 hash-max-ziplist-entries 配置（默认 512 个），同时所有值都小于 hash-max-ziplist-value 配置（默认 64 字节）时，Redis 会使用 ziplist 作为哈希的内部实现。
hashtable（哈希表）：当上述条件不满足时，Redis 则会采用 hashtable 作为哈希的内部实现。
适用场景:储存用户信息，用户主页访问量，组合查询
4 Set
数据结构:HashSet
set 中的元素是不可以重复的，而 list 是可以保存重复元素的。
set 中的元素是无序的，而 list 中的元素是有序的。
set 中的元素不能通过索引下标获取元素，而 list 中的元素则可以通过索引下标获取元素。
除此之外 set 还支持更高级的功能，例如多个 set 取交集、并集、差集等
适用场景:赞，踩，标签，好友关系

5 Zset
数据结构:ziplist/skiplist
ziplist(压缩列表)：当有序集合的元素个数小于 128 个(默认设置)，同时每个元素的值都小于 64 字节(默认设置)，Redis 会采用 ziplist 作为有序集合的内部实现。
skiplist(跳跃表)：当上述条件不满足时，Redis 会采用 skiplist 作为内部编码。
使用场景:排行榜

6 bitmap
数据结构：BitMap 就是通过一个 bit 位来表示某个元素对应的值或者状态, 其中的 key 就是对应元素本身，实际上底层也是通过对字符串的操作来实现
使用场景：统计用户在线状态、活跃用户数、用户签到
7 hyperloglog
数据结构：16384个桶（散列统计,类似set）
适用场景:基数统计（本身有去重功能）
8 geo
数据结构：Zset
使用场景:附近的人、距离计算
9 Stream
这是Redis5.0引入的全新数据结构，用一句话概括Streams就是Redis实现的内存版kafka。支持多播的可持久化的消息队列，用于实现发布订阅功能，借鉴了 kafka 的设计。Redis Stream的结构有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的ID和对应的内容。消息是持久化的，Redis重启后，内容还在。

二 全局Hash表
目的：为了实现基于Key的快速访问，Redis采用了哈希表作为最底层的数据存储结构，如果你了解Java中的HashMap，那么理解Redis的哈希表则应该非常容易，实际上也就是数组+链表的结构，这样一来，我们就可以在O(1)的时间复杂度下快速的查找出所需的Key，并且无论是多少Key都不受影响

Redis 的 key 是 String 类型，但 value 可以是很多类型（String/List/Hash/Set/ZSet等），全局hash表中每个键的key都是名字，value都是器保存的数据类型
typedef struct dictEntry {
void *key;
union {
void *val;
uint64_t u64;
int64_t s64;
double d;
} v;
struct dictEntry *next;
} dictEntry;

typedef struct redisObject {
unsigned type:4; //redisObject的数据类型，4个bits
unsigned encoding:4; //redisObject的编码类型，4个bits
unsigned lru:LRU_BITS;  //redisObject的LRU时间，LRU_BITS为24个bits
int refcount; //redisObject的引用计数，4个字节
void *ptr; //指向值的指针，8个字节
} robj;



三 持久化
RDB：快照持久化
Redis 可以通过创建快照来获得存储在内存里面的数据。创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本( Redis 主从结构，主要用来提高 Redis 性能)，还可以将快照留在原地以便重启服务器的时候使用
优点：
● RDB 是一个非常紧凑的文件，它保存了某个时间点的数据集，非常适用于数据集的备份，比如你可以在每个小时保存一下过去 24 小时内的数据，同时每天保存过去 30 天的数据，这样即使出了问题你也可以根据需求恢复到不同版本的数据集
● RDB 是一个紧凑的单一文件，很方便传送到另一个远端数据中心或者亚马逊的 S3 (可能加密)，非常适用于灾难恢复
● 与 AOF 相比，在恢复大的数据集的时候，RDB 方式会更快一些
缺点：
● 耗时、耗性能
● 不可控、丢失数据
AOF
与快照 RDB 持久化相比，AOF 持久化的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF 方式的持久化，可以通过 appendonly 参数开启。开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 appendonly.aof
aof持久化策略
# 每次有数据修改发生时都会写入 AOF 文件，速度缓慢但是最安全
appendfsync always
# 每秒钟同步一次，显示地将多个写命令同步到硬盘。AOF 默认使用的
appendfsync everysec
# 让操作系统决定何时进行同步，速度最快
appendfsync no

-	RDB	AOF
     启动优先级	低	高
     文件大小	小	大
     恢复速度	快	慢
     数据安全性	丢数据	根据策略决定
     四 redis并发场景
     1 Redis如何保证并发访问数据可靠性
     ● INCR，DECR单原子性指令，类似于Java里面的AtomicInteger（底层依赖操作系统的原子性操作），但只能适用于对数据的简单增减i++，i–；
     ● Lua脚本复合指令，将一段复杂的数据修改操作写到Lua脚本文件中，然后以一个Lua脚本文件为单位，原子性执行，执行脚本文件时不会有其他并发操作；
     ● 分布式锁
     ● 事务MULTI，EXEC
     redis事务
     常用命令为MULTI、EXEC、DISCARD、WATCH
     redis会将一个事务的所有命令序列化，依次执行
     redis不支持回滚操作，编译器错误(命令错误)会导致事务执行失败、运行期错误(逻辑错误正确的命令会执行
     WATCH可以为redis事务提供CAS行为，可以实现乐观锁
     2 分布式锁
     ● A） Java中加锁：通过CAS进行，CAS底层使用了Unsafe类，其方法都是本地方法，依赖操作系统的总线窥探机制以及缓存一致性通信机制实现对数据修改的原子性；
     ● B） Redis中加锁：Redis对数据的修改操作是单线程的，但是读取锁状态，以及写回锁状态的操作不是单线程的，所以存在并发问题，可以考虑使用以上单原子性操作指令或者Lua脚本保证锁状态修改的原子性，通常用SETNX以及DEL单原子性指令完成Redis加锁释放锁（相当于Java中的lock(), unlock()），但是删除锁时一般要包括以下判断逻辑（是否和加锁的是同一个对象），所以释放锁时一般要执行Lua脚本。
     ● 针对该问题，redis 在2.6.12版本过后增加新的解决方案
     ●
     set key value [expiration EX seconds|PX milliseconds] [NX|XX]
     EX seconds:将键的过期时间设置为 seconds 秒。
     SET key value EX seconds 等同于 SETEX key seconds value
     PX millisecounds:将键的过期时间设置为 milliseconds 毫秒。
     SET key value PX milliseconds 等同于 PSETEX key milliseconds value
     NX:只在键不存在的时候，才对键进行设置操作。
     SET key value NX 等同于 SETNX key value
     XX:只在键已经存在的时候，才对键进行设置操作
     例如，使用分布式锁，key不存在的时候才进行设置选用NX，过期时间设置为10s，将SETNX和EXPIRE合二为一


五 内存管理策略
1 回收策略
定期删除+惰性删除
● redis过期的数据不会立马删除，而是等到对象被访问到了(访问key时)，才会检查一遍看是否过期，过期就删除不返回数据
优点：最大化降低了CPU消耗
缺点:过期key有可能一直存放在内存中，有内存泄漏风险
● 定期过期是给每隔一段时间去寻找已过期的key,找到并删除。
主要步骤：
1：在server.c文件里面有个serverCron的时间方法，计算出了每隔100ms （可配置hz,默认每秒执行10次）就随机扫描一次设置了过期时间的数据
2：扫描是以hash桶维度去扫描的，只要被扫描到的桶就会扫描桶里所有的数据
(如下图橙色数字1，2，3下标相当于第一个桶，第二桶，箭头所指的节点数据就是桶里所有的数据)，一次最多扫描20个设置过期时间的key,超过20个就不会扫描下一个桶了，最多扫描400个桶。
3：扫描到的数据检测是否已过期，过期就删除
4：如果400个桶都没有扫描到设置过期时间的数据，或者扫出的key删除的比例大于10%(可配置)，继续扫描。
5：每循环16次就会检测定时时长，超过指定时间结束定期删除操作。
2 淘汰策略(当内存满了，再设置键时怎么淘汰已有键)
● noeviction:默认的淘汰方式，当使用的内存超过maxmemory设置的值，会报错。只能读不能写。
● volatile-ttl：在设置了过期时间的数据中筛选，越早过期的优先被删除。
● volatile-random：在设置了过期时间的数据中随机筛选并删除。
● allkeys-random：在所有数据中随机筛选并删除。
● volatile-LRU：在设置了过期时间的数据中使用LRU算法进行淘汰。
● allkeys-LRU：在所有数据中使用LRU算法进行淘汰。
● volatile-LFU：在设置了过期时间的数据中使用LFU算法进行淘汰
● allkeys-LFU：在所有数据中使用LFU算法淘汰数据
LRU:最近最少使用策略，以时间维度衡量
LFU：最近最不经常使用：以次数衡量，前16位bit的时间+后8位bit次数，时效性问题是加入了时间的维度，通过时间+次数的维度算法保证了时效性。

六 缓存击穿、缓存雪崩、缓存穿透
三个问题都是因为请求直接达到了DB，使得DB压力过高
1 缓存雪崩
原因：多个Key在同一时刻同时过期，导致请求直接查询数据库
解决办法：
● 设置过期时间加个随机值，是缓存失效时间分散开；
● 设置多级缓存机制：nginx缓存+redis缓存
● 使用队列，保证不会有大量并发请求访问数据库
2 缓存击穿
原因：由于热点Key过期，多个求子直接达到服务器
解决办法：
● 启动时预先缓存热门数据
● 适当延长过期时间
● 适时进行调整，更新缓存时间
● 设置永不过期
3 缓存穿透
原因：请求的数据在缓存中不存在，同时在数据库中也不存在
解决办法：
● 对空值缓存
● 设置访问名单
● 布隆过滤器
布隆过滤器：
数据结构：有一个大型二进制数组+多个无偏hash函数组成
原理：存在多个无偏hash函数，如果通过其中一个hash我们得出元素不在集合中，那么元素一定不在集合中；只有经过所有hash函数判定集合在元素中，那么才认为这个元素在集合中。一般用于在大数据集合中判断某个元素是否存在，判断不存在一定不存在，判定存在不一定存在，有一定的误判率。
● 解决Redis缓存穿透问题（面试重点）
● 邮件过滤，使用布隆过滤器来做邮件黑名单过滤
● 对爬虫网址进行过滤，爬过的不再爬
● 解决新闻推荐过的不再推荐(类似抖音刷过的往下滑动不再刷到)
● HBase\RocksDB\LevelDB等数据库内置布隆过滤器，用于判断数据是否存在，可以减少数据库的IO请求

七 redis集群问题
1 性能优化
● Master 不要做持久化操作，交给slave进行
● 对于数据比较重要的要开启AOF持久化，appendonly yes
● 主从集群结构采用链表
● 内存优化：存储对象数据尽量用散列表，多个string类型可以采用hash存储，因为hash底层编码ziplist空间连续
2 同步机制
主机第一次接受同步命令时，做一次bgsave生成RDB文件，传输RDB文件到slave，在此期间如果有新的命令将进入缓冲区，从机接受RDB问件进行数据同步，同步完成后执行缓冲区命令没接下来主机每执行一条命令，从机也会执行一个命令；

3 集群原理
Redis集群采用去中心化的思想，没有中心节点的说法，对于客户端来说，整个集群可以看成一个整体，可以连接任意一个节点进行操作，就像操作单一Redis实例一样，不需要任何代理中间件，当客户端操作的key没有分配到该node上时，Redis会返回转向指令，指向正确的node。
Redis也内置了高可用机制，支持N个master节点，每个master节点都可以挂载多个slave节点，当master节点挂掉时，集群会提升它的某个slave节点作为新的master节点。
集群分布算法：hash槽算法
Redis集群采用的算法是哈希槽分区算法。Redis集群中有16384个哈希槽（槽的范围是 0 -16383，哈希槽），将不同的哈希槽分布在不同的Redis节点上面进行管理，也就是说每个Redis节点只负责一部分的哈希槽。在对数据进行操作的时候，集群会对使用CRC16算法对key进行计算并对16384取模（slot = CRC16(key)%16383），得到的结果就是 Key-Value 所放入的槽，通过这个值，去找到对应的槽所对应的Redis节点，然后直接到这个对应的节点上进行存取操作。
使用哈希槽的好处就在于可以方便的添加或者移除节点，并且无论是添加删除或者修改某一个节点，都不会造成集群不可用的状态。当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了；当需要移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了；哈希槽数据分区算法具有以下几种特点：
● 解耦数据和节点之间的关系，简化了扩容和收缩难度；
● 节点自身维护槽的映射关系，不需要客户端代理服务维护槽分区元数据
● 支持节点、槽、键之间的映射查询，用于数据路由，在线伸缩等场景

4 集群会出现写操作丢失
以下情况可能导致写操作丢失：
1、过期 key 被清理。
2、最大内存不足，导致 Redis 自动清理部分 key 以节省空间。
3、主库故障后自动重启，从库自动同步。
4、单独的主备方案，网络不稳定触发哨兵的自动切换主从节点，切换期间会有数据丢失。
